"""*******************************************************************************
* Licensed Materials - Property of IBM
* (c) Copyright IBM Corporation ${year}. All Rights Reserved.
*
* Note to U.S. Government Users Restricted Rights:
* Use, duplication or disclosure restricted by GSA ADP Schedule
* Contract with IBM Corp.
*******************************************************************************"""

"""
Author: Utkarsh Desai
Maintenance: Utkarsh Desai
"""

import sys
import json
import utils
from metrics import Metrics
from monolith import Monolith

# Keys/names for metrics
coverage_key                = "coverage"
conceptual_independence_key = "conceptual_independence"
modularity_key              = "modularity"
structural_cohesivity_key   = "structural_cohesivity"
structural_modularity_key   = "structural_modularity"

class PartitionEvaluator(object):
    """
    Main class to trigger evaluation of partitions generated by CMA
    Refer to the end of the file for example usage
    """

    def __init__(self, partition_file, icu_file=None, callgraph_file=None, entrypoint_file=None, output_file=None):
        self.output_file = output_file

        with open(partition_file) as json_file:
            self.data = json.load(json_file)

        self._validate_schema()
        print("Schema validated.")

        self.app = None
        if icu_file is not None and callgraph_file is not None and entrypoint_file is not None:
            print("Parsing ICU and Call graph .. ")
            self.app = Monolith(icu_file, callgraph_file, entrypoint_file)

    def evaluate_clusters(self):
        """
        Evaluate if the generated partitions can be explained via some static analysis feature
        """
        if self.app is None:
            print("Unable to evaluate. Please provide ICU and Call-graph information.")
            return

        clusters, edges = utils.get_clusters_and_edges(self.data)

        # Store evaluation results for each cluster here:
        evaluation_results = []

        # Get list of clusters
        for clusterid in clusters.keys():
            cm = clusters[clusterid]
            members = cm['classes']
            all_members = list(members)

            # Result and inconsistencies for this cluster
            result = {'clusterid':clusterid, 'members':all_members}
            inconsistencies = []

            ### Check for ICU link
            missing_icu_link_ids = []
            # for mem in all_members:
            #     print("\t", mem)

            all_idxs = [self.app.icuclass2idx[m] for m in all_members]  # all classes in this cluster
            found_idxs = [] # a list of classes we found have some relation with some other class in cluster
            for i in all_idxs:  # this loop denotes the class under consideration
                for j in all_idxs:  # this loop denotes all classes
                    if i == j:
                        continue
                    if self.app.icu[i,j] > 0 or self.app.icu[j,i] > 0:
                        found_idxs.append(i)
                        break
            # From all classes, if we have not found some class in link with another class, we capture it
            missing_icu_link_ids = [i for i in all_idxs if i not in found_idxs]
            missing_icu_link_classes = [self.app.idx2icuclass[idx] for idx in missing_icu_link_ids]
            #print("*** Classes in cluster", clusterid, "with no ICU link - Total:", len(missing_icu_link_ids), missing_icu_link_classes)
            inconsistencies.append({'type':'ICU', 'classes':missing_icu_link_classes})

            ### Check for entrypoint link
            reverse_ep = utils.reverse_entrypoint(self.app.entrypoints)

            missing_ep_link_classes = []
            for i, ci in enumerate(missing_icu_link_classes): # this loop denotes the class under consideration
                common_ep = 0
                for j,cj in enumerate(all_members):  # this loop denotes all classes
                    if ci == cj:
                        continue
                    ep_i = reverse_ep.get(ci)
                    ep_j = reverse_ep.get(cj)
                    if ep_i is None or ep_j is None:
                        continue
                    for ei in ep_i:
                        if ei in ep_j:
                            common_ep += 1
                            break
                if common_ep == 0:
                    missing_ep_link_classes.append(ci)
            #print("Classes in this cluster with no entrypoints common with other classes:", len(missing_ep_link_classes), missing_ep_link_classes)
            inconsistencies.append({'type':'EntryPoint', 'classes':missing_ep_link_classes})

            # Add to this cluster's result
            result['inconsistencies'] = inconsistencies
            # Add this clnuster's result to the glocal result for all clusters
            evaluation_results.append(result)

            ### TODO: Finally check if the classes occur in cooccurrence matrix (highly unlikely if they dont share entrypoint, but still)

        evaluation_result = {'evaluation_results':evaluation_results}

        #print("Num clusters:", len(clusters))
        #print(evaluation_result)
        return evaluation_result

    def compute_metrics(self):
        """
        Compute all available metrics for this partitioning
        """
        coverage = Metrics.get_coverage(self.data)
        conceptual_independence = Metrics.get_conceptual_independence(self.data)
        modularity = Metrics.get_modularity(self.data)
        structural_cohesivity = Metrics.get_structural_cohesivity(self.data)
        structural_modularity = Metrics.get_structural_modularity(self.data)

        self.result = { coverage_key : coverage,
                        conceptual_independence_key : conceptual_independence,
                        modularity_key : modularity,
                        structural_cohesivity_key : structural_cohesivity,
                        structural_modularity_key : structural_modularity
                    }

        if self.output_file is not None:
            with open(self.output_file, 'w') as f:
                json.dump(self.result, f)
            print("Output written to file:", self.output_file)

        return self.result

    def _validate_schema(self):
        pass

if __name__ == "__main__":

    if len(sys.argv) < 2:
        print("Arguments: <partition-json-file> <(optional)output-file> <icufile(optional)> <callgraphfile(optional)> <entrypointfile(optional)>")
        sys.exit(1)

    inputfile = sys.argv[1]
    outputfile = None
    icufile = None
    callgraphfile = None
    entrypointfile = None
    print(len(sys.argv), "--")
    if len(sys.argv) > 2:
        outputfile = sys.argv[2]
    if len(sys.argv) == 6:
        icufile =sys.argv[3]
        callgraphfile = sys.argv[4]
        entrypointfile = sys.argv[5]

    eval = PartitionEvaluator(partition_file=inputfile, output_file=outputfile, icu_file=icufile, callgraph_file=callgraphfile, entrypoint_file=entrypointfile)
    metrics = eval.compute_metrics()
    print("Result:", metrics)
    eval_result = eval.evaluate_clusters()
    print("Evaluation:", eval_result)
